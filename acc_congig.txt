accelerate_config = {
    "compute_environment": "LOCAL_MACHINE",
    "distributed_type": "FSDP",
    "fsdp_config": {
        "fsdp_sharding_strategy": 2,
        "fsdp_offload_params": True,
        "fsdp_auto_wrap_policy": "TRANSFORMER_BASED_WRAP",
        "fsdp_use_orig_params": True,
        "fsdp_state_dict_type": "SHARDED_STATE_DICT",
        "fsdp_cpu_ram_efficient_loading": True,
        "fsdp_activation_checkpointing": True,
        "fsdp_forward_prefetch": False,
        "fsdp_backward_prefetch": None,
        "fsdp_limit_all_gathers": False
    },
    "use_cpu": False,
    "mixed_precision": "no",
    "machine_rank": 0,
    "num_machines": 1,
    "num_processes": 2,
    "gpu_ids": "all",
    "main_process_ip": None,
    "main_process_port": None,
    "main_training_function": "main",
    "dynamo_backend": "inductor",
    "dynamo_use_compile": True,
    "dynamo_use_custom_settings": False,
    "deepspeed_config": {},
    "tpu_use_cluster": False,
    "tpu_use_sudo": False,
    "tpu_env": {},
    "same_network": True,
    "zero3_init_flag": False,
    "tpu_name": None,
    "use_megatron_lm": False,
    "megatron_lm_config": {},
    "parallel_mode_config": {
        "use_parallel_mode": True,
        "data_parallel_size": 2,
        "fsdp_parallel_size": 2,
        "tensor_parallel_size": 1,
        "context_parallel_size": 1
    }
}
